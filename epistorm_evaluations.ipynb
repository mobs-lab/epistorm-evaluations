{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53044182-bf0b-4dcd-b811-eee167b40de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from epiweeks import Week\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9f67dd-2b72-4f6f-bad4-584da6ada67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.13.1\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98848f4d-50db-457e-94cf-aaf8d913e35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b21d823-76a1-420b-a2ef-dd7b8318c14f",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b823c2e-43ad-4f25-9ec2-68864e3cffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to download flusight model predictions and surveillance data\n",
    "\n",
    "def pull_flusight_predictions(model,date):\n",
    "    \"\"\"pull_flusight_predictions. Load predictions of the model saved by the Flusight Forecast hub\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : str\n",
    "        Model name on the\n",
    "    dates : list or string\n",
    "        List of potential dates in the iso format, e.g., 'yyyy-mm-dd', for the submission.\n",
    "    \"\"\"\n",
    "    predictions = None\n",
    "    \n",
    "    url = f\"https://raw.githubusercontent.com/cdcepi/Flusight-forecast-hub/main/model-output/{model}/{date}-{model}\"\n",
    "    for ext in [\".csv\",\".gz\",\".zip\",\".csv.zip\",\".csv.gz\"]:\n",
    "        try:\n",
    "            predictions = pd.read_csv(url+ext,dtype={'location':str},parse_dates=['target_end_date'])\n",
    "        except:\n",
    "            pass\n",
    "    if predictions is None:\n",
    "        print(f\"Data for model {model} and date {date} unavailable\")\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def pull_surveillance_data():\n",
    "    \"\"\"pull_surveillance_data. Load hospitalization admissions surveillance data\n",
    "    \"\"\"\n",
    "    \n",
    "    url = f\"https://raw.githubusercontent.com/cdcepi/FluSight-forecast-hub/main/target-data/target-hospital-admissions.csv\"\n",
    "    return pd.read_csv(url, dtype={'location':str})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cd36fa6-150b-47d2-8ce7-3e82281b708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and save surveillance data\n",
    "surv = pull_surveillance_data()\n",
    "surv.to_parquet(f\"./dat/target-hospital-admissions.pq\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "475e7a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "surv = pd.read_parquet(f\"./dat/target-hospital-admissions.pq\")\n",
    "surv['Unnamed: 0'] = 0"
   ]
  },
  {
   "cell_type": "raw",
   "id": "745b3b96-e522-432b-aac2-b5ecdabd539f",
   "metadata": {},
   "source": [
    "models = ['CADPH-FluCAT_Ensemble', 'CEPH-Rtrend_fluH',  'CMU-TimeSeries', 'CU-ensemble', 'FluSight-baseline',\n",
    "          'FluSight-ensemble','FluSight-equal_cat', 'FluSight-lop_norm', 'GH-model', 'GT-FluFNP', 'ISU_NiemiLab-ENS', \n",
    "          'ISU_NiemiLab-NLH','ISU_NiemiLab-SIR', 'LUcompUncertLab-chimera', 'LosAlamos_NAU-CModel_Flu', \n",
    "          'MIGHTE-Nsemble','MOBS-GLEAM_FLUH', 'NIH-Flu_ARIMA', 'PSI-PROF', 'SGroup-RandomForest', 'SigSci-CREG', \n",
    "          'SigSci-TSENS','Stevens-GBR', 'UGA_flucast-Copycat', 'UGA_flucast-INFLAenza', 'UGA_flucast-OKeeffe', \n",
    "          'UGuelph-CompositeCurve', 'UGuelphensemble-GRYPHON', 'UM-DeepOutbreak', 'UMass-flusion', \n",
    "          'UMass-trends_ensemble', 'UNC_IDD-InfluPaint', 'UVAFluX-Ensemble', 'VTSanghani-Ensemble', 'cfa-flumech',\n",
    "          'cfarenewal-cfaepimlight', 'fjordhest-ensemble', 'NU_UCSD-GLEAM_AI_FLUH', 'PSI-PROF_beta',\n",
    "          'JHU_CSSE-CSSE_Ensemble', 'FluSight-national_cat', 'FluSight-ens_q_cat', 'FluSight-baseline_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2055db05-7fe1-4a76-ae2f-1a1e0a2c8cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting all target dates that exist in the surveillance file\n",
    "dates = pd.unique(surv.date)\n",
    "\n",
    "#selecting just models used in the dashboard for now\n",
    "#will need to expand eventually whether we keep the parquet implementation or pull files from the flusight repo as a submodule\n",
    "models = ['CEPH-Rtrend_fluH', 'FluSight-baseline', 'FluSight-ensemble', 'MIGHTE-Nsemble', 'MOBS-GLEAM_FLUH', 'NU_UCSD-GLEAM_AI_FLUH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6805cfdd-aac5-42e7-9d38-74097fafc0c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for model CEPH-Rtrend_fluH and date 2023-06-03 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-06-10 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-06-17 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-06-24 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-07-01 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-07-08 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-07-15 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-07-22 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-07-29 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-08-05 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-08-12 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-08-19 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-08-26 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-09-02 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-09-09 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-09-16 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-09-23 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-09-30 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-10-07 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-06-03 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-06-10 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-06-17 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-06-24 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-07-01 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-07-08 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-07-15 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-07-22 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-07-29 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-08-05 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-08-12 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-08-19 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-08-26 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-09-02 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-09-09 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-09-16 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-09-23 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-09-30 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-10-07 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-06-03 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-06-10 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-06-17 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-06-24 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-07-01 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-07-08 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-07-15 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-07-22 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-07-29 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-08-05 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-08-12 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-08-19 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-08-26 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-09-02 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-09-09 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-09-16 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-09-23 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-09-30 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-10-07 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-06-03 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-06-10 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-06-17 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-06-24 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-07-01 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-07-08 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-07-15 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-07-22 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-07-29 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-08-05 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-08-12 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-08-19 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-08-26 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-09-02 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-09-09 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-09-16 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-09-23 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-09-30 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-10-07 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-06-03 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-06-10 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-06-17 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-06-24 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-07-01 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-07-08 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-07-15 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-07-22 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-07-29 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-08-05 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-08-12 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-08-19 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-08-26 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-09-02 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-09-09 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-09-16 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-09-23 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-09-30 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-10-07 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-06-03 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-06-10 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-06-17 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-06-24 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-07-01 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-07-08 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-07-15 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-07-22 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-07-29 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-08-05 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-08-12 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-08-19 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-08-26 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-09-02 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-09-09 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-09-16 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-09-23 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-09-30 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-10-07 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-10-14 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-10-21 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-10-28 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-11-04 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-11-11 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-11-18 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-11-25 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    for date in dates:\n",
    "        try:\n",
    "            predictions = pull_flusight_predictions(model,date)\n",
    "\n",
    "            predictions.to_parquet(f'./dat/{model}_{date}.pq', index=False)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ebbec-69bc-4dbf-973f-048728983389",
   "metadata": {},
   "source": [
    "# Classes and Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b66a9f77-bc14-430c-bd38-cfaa2218054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for calculating scores of the forecasts against the surveillance data\n",
    "\n",
    "\n",
    "class Forecast_Eval:\n",
    "    \"\"\" Used for scoring and evaluating flu forecasting predictions from the Flusight challenge for the \n",
    "        2023-24 season\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, obsdf, target,  start_week = False, end_week = False):\n",
    "        self.df = df # pandas Dataframe: input dataframe of forecasts with all scenarios, locations, and quantiles\n",
    "        self.obsdf = obsdf # pandas Dataframe: input of surveillance data of interest\n",
    "        self.target = target # str: target metric of interest (case, death, hospitalization)\n",
    "        self.start_week = start_week # epiweek: beginning of observations of interest\n",
    "        self.end_week = end_week # epiweek: end of observations of interest\n",
    "        \n",
    "    def process_observations(self, data, value_col='value', t_col='date', other_ind_cols=None):\n",
    "        \"\"\"\n",
    "    \n",
    "        Parameters:\n",
    "        - data: pd.DataFrame\n",
    "            The input data containing observational information.\n",
    "        - value_col: str\n",
    "            The column name representing the value column.\n",
    "        - t_col: str\n",
    "            The column name representing the time column.\n",
    "        - other_ind_cols: list\n",
    "            A list of additional independent columns for sorting.\n",
    "\n",
    "        Returns:\n",
    "        - pd.DataFrame with additional helper functions for accessing specific columns.\n",
    "        \"\"\"\n",
    "        # Ensure required columns are present\n",
    "        if value_col not in data.columns or t_col not in data.columns:\n",
    "            raise ValueError(f\"DataFrame must contain '{value_col}' and '{t_col}' columns.\")\n",
    "\n",
    "        # Prepare independent columns and sort data\n",
    "        ind_cols = [t_col] + (other_ind_cols if other_ind_cols else [])\n",
    "        sorted_data = data.sort_values(by=ind_cols).reset_index(drop=True)\n",
    "\n",
    "        # Define helper functions to access specific columns and set them as attributes\n",
    "        sorted_data.get_value = lambda: sorted_data[value_col].to_numpy()\n",
    "        sorted_data.get_t = lambda: sorted_data[t_col].to_numpy()\n",
    "        sorted_data.get_x = lambda: sorted_data[ind_cols].to_numpy()\n",
    "        sorted_data.get_unique_x = lambda: np.unique(np.array(sorted_data[ind_cols].to_numpy(), dtype=str), axis=0)\n",
    "\n",
    "        return sorted_data      \n",
    "            \n",
    "            \n",
    "    def get_observations(self, target_location):\n",
    "        \"\"\" get_observations. Load and filter surveillance data for a certain location.\n",
    "        Parameters\n",
    "        ----------\n",
    "        target_location : str\n",
    "            location to filter surveillance data by\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.target == 'hosp':\n",
    "            target_obs = 'hospitalization'\n",
    "        else:\n",
    "            target_obs = self.target\n",
    "            \n",
    "        # read in observations dataframe\n",
    "        \n",
    "        observations = self.obsdf.copy().drop(columns= ['Unnamed: 0', 'weekly_rate'])\n",
    "        observations['date'] = pd.to_datetime(observations['date'])\n",
    "\n",
    "        #filter start - end week\n",
    "        if self.start_week:\n",
    "            observations = observations[(observations['date'] >= pd.to_datetime(self.start_week.startdate())) ]\n",
    "            \n",
    "        if self.end_week:\n",
    "            observations = observations[(observations['date'] <= pd.to_datetime(self.end_week.enddate()))]\n",
    "                                \n",
    "        #filter location\n",
    "        observations = observations[observations['location'] == target_location]\n",
    "\n",
    "        #aggregate to weekly\n",
    "        observations = observations.groupby(['location', pd.Grouper(key='date', freq='W-SAT')]).sum().reset_index()\n",
    "\n",
    "        #transform to Observation object\n",
    "        observations = self.process_observations(observations)\n",
    "\n",
    "        return observations\n",
    "    \n",
    "    def process_predictions(self, data, value_col='value', quantile_col='output_type_id', type_col='output_type',\n",
    "                        t_col='target_end_date', other_ind_cols=None):\n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters:\n",
    "        - data: pd.DataFrame\n",
    "            The input data containing prediction information.\n",
    "        - value_col: str\n",
    "            Column label for the predictions' value.\n",
    "        - quantile_col: str\n",
    "            Column label for the predictions' quantile.\n",
    "        - type_col: str\n",
    "            Column label for the type of predictions (e.g., quantile or point).\n",
    "        - t_col: str\n",
    "            Column label for the timestamp of predictions.\n",
    "        - other_ind_cols: list\n",
    "            List of other independent variable columns (e.g., location).\n",
    "\n",
    "        Returns:\n",
    "        - pd.DataFrame with additional helper methods to access specific data arrays or filtered predictions.\n",
    "        \"\"\"\n",
    "        # Ensure required columns are present\n",
    "        if not all(col in data.columns for col in [value_col, quantile_col, t_col]):\n",
    "            raise ValueError(f\"DataFrame must contain '{value_col}', '{quantile_col}', and '{t_col}' columns.\")\n",
    "        if other_ind_cols and not all(col in data.columns for col in other_ind_cols):\n",
    "            raise ValueError(\"DataFrame must contain all specified independent columns.\")\n",
    "\n",
    "        # Define independent columns and sort data\n",
    "        ind_cols = [t_col] + (other_ind_cols if other_ind_cols else [])\n",
    "        sorted_data = data.sort_values(by=ind_cols).reset_index(drop=True)\n",
    "\n",
    "        # Set default value for type column if missing\n",
    "        if type_col not in sorted_data.columns:\n",
    "            sorted_data[type_col] = 'quantile'\n",
    "\n",
    "        # Attach helper methods as attributes of the DataFrame\n",
    "        sorted_data.get_t = lambda: sorted_data[t_col].to_numpy()\n",
    "        sorted_data.get_x = lambda: sorted_data[ind_cols].to_numpy()\n",
    "        sorted_data.get_unique_x = lambda: np.unique(np.array(sorted_data[ind_cols].to_numpy(), dtype=str), axis=0)\n",
    "\n",
    "      \n",
    "\n",
    "        return sorted_data\n",
    "\n",
    "    \n",
    "    def format_forecasts_all(self, dfformat):\n",
    "        \"\"\" format_forecasts_all. Get forecasts into standard format to use for scoring.\n",
    "        Parameters\n",
    "        ----------\n",
    "        dfformat : pandas DataFrame\n",
    "            dataframe of forecast output used for formatting\n",
    "        \"\"\"\n",
    "        \n",
    "        pred = dfformat.copy()\n",
    "        pred = pred[pred.output_type == 'quantile'] # only keep quantile predictions\n",
    "        pred['target_end_date'] = pd.to_datetime(pred['target_end_date']) #make sure dates are in datetime format\n",
    "        if self.start_week:\n",
    "            pred = pred[(pred['target_end_date'] >= pd.to_datetime(self.start_week.startdate()))] # filter dates\n",
    "        \n",
    "        if self.end_week:\n",
    "            pred = pred[(pred['target_end_date'] <= pd.to_datetime(self.end_week.enddate()))] # filter dates\n",
    "        \n",
    "        pred['output_type_id'] = pred[\"output_type_id\"].astype(float) # make sure quantile levels are floats\n",
    "        \n",
    "        return pred\n",
    "        \n",
    "    \n",
    "\n",
    "class Scoring(Forecast_Eval):\n",
    "    \"\"\" calculate score values for probabilistic epidemic forecasts \n",
    "    find WIS, MAPE, and coverage over whole projection window as well as timestamped for every week.\n",
    "    score dataframe must have 'Model' column to differentiate and calculate scores for different models\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, obsdf, target, start_week = False, \n",
    "                 end_week = False):\n",
    "        super().__init__(df, obsdf, target, start_week, end_week)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def interval_score(self, observation, lower, upper, interval_range, specify_range_out=False):\n",
    "        \"\"\"interval_score.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observation : array_like\n",
    "            Vector of observations.\n",
    "        lower : array_like\n",
    "            Prediction for the lower quantile.\n",
    "        upper : array_like\n",
    "            Prediction for the upper quantile.\n",
    "        interval_range : int\n",
    "            Percentage covered by the interval. For instance, if lower and upper correspond to 0.05 and 0.95\n",
    "            quantiles, interval_range is 90.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : dict\n",
    "            Dictionary containing vectors for the interval scores, but also the dispersion, underprediction and\n",
    "            overprediction.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError:\n",
    "            If the observation, the lower and upper vectors are not the same length or if interval_range is not\n",
    "            between 0 and 100\n",
    "        \"\"\"\n",
    "        if len(lower) != len(upper) or len(lower) != len(observation):\n",
    "            raise ValueError(\"vector shape mismatch\")\n",
    "        if interval_range > 100 or interval_range < 0:\n",
    "            raise ValueError(\"interval range should be between 0 and 100\")\n",
    "\n",
    "        #make sure vector operation works\n",
    "        obs,l,u = np.array(observation),np.array(lower),np.array(upper)\n",
    "\n",
    "        alpha = 1-interval_range/100 #prediction probability outside the interval\n",
    "        dispersion = u - l\n",
    "        underprediction = (2/alpha) * (l-obs) * (obs < l)\n",
    "        overprediction = (2/alpha) * (obs-u) * (obs > u)\n",
    "        score = dispersion + underprediction + overprediction\n",
    "        if not specify_range_out:\n",
    "            out = {'interval_score': score,\n",
    "                   'dispersion': dispersion,\n",
    "                   'underprediction': underprediction,\n",
    "                   'overprediction': overprediction}\n",
    "        else:\n",
    "            out = {f'{interval_range}_interval_score': score,\n",
    "                   f'{interval_range}_dispersion': dispersion,\n",
    "                   f'{interval_range}_underprediction': underprediction,\n",
    "                   f'{interval_range}_overprediction': overprediction}\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "    def timestamp_wis(self,observations, predsfilt, interval_ranges =[10,20,30,40,50,60,70,80,90,95,98]):\n",
    "        \"\"\"timestamp_wis.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observations : Observations object\n",
    "            Specialized dateframe for the observations across time.\n",
    "        predictions : Predictions object\n",
    "            Specialized dateframe for the predictions (quantile and point) across time.\n",
    "        interval_ranges : list of int\n",
    "            Percentage covered by each interval. For instance, if interval_range is 90, this corresponds\n",
    "            to the interval for the 0.05 and 0.95 quantiles.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df : DataFrame\n",
    "            DataFrame containing the weighted interval score across time.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError:\n",
    "            If the independent columns do not match for observations and predictions.\n",
    "            If the median is not calculated.\n",
    "            If the point estimate is not included.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        quantiles = np.array(predsfilt.sort_values(by='output_type_id').output_type_id)\n",
    "\n",
    "        qs = []\n",
    "        for q in quantiles:\n",
    "            df = predsfilt[predsfilt.output_type_id==q].sort_values(by='target_end_date')\n",
    "            val = np.array(df.value)\n",
    "            qs.append(val)\n",
    "\n",
    "\n",
    "        Q = np.array(qs) # quantiles array\n",
    "        y = np.array(observations.value) # observations array\n",
    "\n",
    "        # calculate WIS\n",
    "        WIS = np.zeros(len(y))\n",
    "\n",
    "        for i in range(len(quantiles) // 2):\n",
    "            interval_range = 100*(quantiles[-i-1]-quantiles[i])\n",
    "            #print(interval_range)\n",
    "            alpha = 1-(quantiles[-i-1]-quantiles[i])\n",
    "            IS = self.interval_score(y,Q[i],Q[-i-1],interval_range)\n",
    "            WIS += IS['interval_score']*alpha/2\n",
    "        WIS += 0.5*np.abs(Q[11] - y)\n",
    "\n",
    "        WISlist = np.array(WIS) / (len(interval_ranges) + 0.5)\n",
    "\n",
    "        df = pd.DataFrame({'Model':predsfilt.Model.unique(), 'location':predsfilt.location.unique(), 'horizon':predsfilt.horizon.unique(),\n",
    "                           'reference_date':predsfilt.reference_date.unique(), 'target_end_date':predsfilt.target_end_date.unique(),\n",
    "                           'wis':WISlist[0]},index=[0])\n",
    "\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def coverage(self,observation,lower,upper):\n",
    "        \"\"\"coverage. Output the fraction of observations within lower and upper.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observation : array_like\n",
    "            Vector of observations.\n",
    "        lower : array_like\n",
    "            Prediction for the lower quantile.\n",
    "        upper : array_like\n",
    "            Prediction for the upper quantile.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        cov : float\n",
    "            Fraction of observations within the lower and upper bound.\n",
    "\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError:\n",
    "            If the observation, the lower and upper vectors are not the same length.\n",
    "        \"\"\"\n",
    "        if len(lower) != len(upper) or len(lower) != len(observation):\n",
    "            raise ValueError(\"vector shape mismatch\")\n",
    "\n",
    "        #make sure vector operation works\n",
    "        obs,l,u = np.array(observation),np.array(lower),np.array(upper)\n",
    "\n",
    "        return np.mean(np.logical_and(obs >= l, obs <= u))\n",
    "\n",
    "\n",
    "    def all_coverages_from_df(self,observations, predictions, interval_ranges=[10,20,30,40,50,60,70,80,90,95,98],\n",
    "                              **kwargs):\n",
    "        \"\"\"all_coverages_from_df.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observations : DataFrame object\n",
    "            Dateframe for the observations across time.\n",
    "        predictions : DataFrame object\n",
    "            Dateframe for the predictions (intervals) across time.\n",
    "        interval_ranges : list of int\n",
    "            Percentage covered by each interval. For instance, if interval_range is 90, this corresponds\n",
    "            to the interval for the 0.05 and 0.95 quantiles.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : dict\n",
    "            Dictionary containing the coverage for all interval ranges.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError:\n",
    "            If the independent columns do not match for observations and predictions.\n",
    "        \"\"\"\n",
    "        #verify that the independent variable columns (usually dates and location) matches\n",
    "        # if not np.array_equal(observations.get_unique_x(), predictions.get_unique_x()):\n",
    "            # raise ValueError(\"Values for the independent columns do not match\")\n",
    "\n",
    "        out = dict()\n",
    "        for interval_range in interval_ranges:\n",
    "            q_low,q_upp = round(0.5-interval_range/200,3),round(0.5+interval_range/200,3)\n",
    "            cov = self.coverage(list(observations.value),\n",
    "                           list(predictions[predictions.output_type_id ==q_low].value),\n",
    "                           list(predictions[predictions.output_type_id==q_upp].value))\n",
    "            out[f'{interval_range}_cov'] = cov\n",
    "        return out\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_mape(self):\n",
    "        \"\"\" get_mape. Calculate MAPE (mean absolute percentage error) for each date of a forecast. If \n",
    "            surveillance data point is equal to zero, the score is undefined (Nan).\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        predictions = self.df.copy()\n",
    "        \n",
    "        # get point forecast, here we say it is the median\n",
    "        predictions = predictions[predictions['output_type_id'] == 0.5] # get point forecast, here we say it is the median\n",
    "\n",
    "        mapedf = pd.DataFrame()\n",
    "\n",
    "        # find mape for a given model and location over projection period\n",
    "        for model in predictions.Model.unique():\n",
    "            for target_location in predictions.location.unique():\n",
    "\n",
    "                    if target_location in ['60','66','69', '72', '78']:\n",
    "                        continue\n",
    "\n",
    "                    observations = self.get_observations(target_location)\n",
    "                    \n",
    "\n",
    "                    pred = predictions[(predictions.location == target_location) & (predictions.Model==model)]\n",
    "                    pred = self.process_predictions(pred, t_col = 'target_end_date',quantile_col='output_type_id')### self.process_predictions\n",
    "                    \n",
    "                    observations = observations[observations.date.isin(pred.target_end_date.unique())]\n",
    "\n",
    "                    n = observations.shape[0]\n",
    "\n",
    "                    realvals = list(observations.value)\n",
    "                    predvals = list(pred.value)\n",
    "\n",
    "                    \n",
    "                    if len(predvals) == 0:\n",
    "                        continue\n",
    "\n",
    "                    if realvals[0] == 0:\n",
    "                        n = n - 1\n",
    "                        continue\n",
    "\n",
    "                    err = abs((realvals[0]-predvals[0])/realvals[0]) # find relative error\n",
    "\n",
    "\n",
    "                    if n == 0:\n",
    "                        mape = None\n",
    "                    else:\n",
    "                        mape = err # calculate mape\n",
    "\n",
    "\n",
    "                    data = {'Model': model,'Location': target_location, 'MAPE':mape}\n",
    "\n",
    "                    # store in pandas DataFrame\n",
    "                    newdf = pd.DataFrame(data, index=[1])\n",
    "\n",
    "                    mapedf = pd.concat([mapedf, newdf])\n",
    "\n",
    "        mapedf = mapedf.reset_index()\n",
    "        mapedf = mapedf.drop(['index'], axis=1)\n",
    "\n",
    "        return mapedf\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dcb7f3-a01b-4daf-877a-2d5c0e427fe8",
   "metadata": {},
   "source": [
    "# Calculate Scores\n",
    "\n",
    "## Instantiate Forecast_Eval Class and Format Data for Scoring\n",
    "\n",
    "I'm keeping the dates and models specified earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc316645-5c70-4a96-ad94-ce79afeb30e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-06-03.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-06-10.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-06-17.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-06-24.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-07-01.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-07-08.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-07-15.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-07-22.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-07-29.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-08-05.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-08-12.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-08-19.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-08-26.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-09-02.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-09-09.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-09-16.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-09-23.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-09-30.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-10-07.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-06-03.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-06-10.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-06-17.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-06-24.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-07-01.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-07-08.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-07-15.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-07-22.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-07-29.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-08-05.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-08-12.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-08-19.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-08-26.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-09-02.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-09-09.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-09-16.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-09-23.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-09-30.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-10-07.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-06-03.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-06-10.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-06-17.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-06-24.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-07-01.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-07-08.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-07-15.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-07-22.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-07-29.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-08-05.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-08-12.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-08-19.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-08-26.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-09-02.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-09-09.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-09-16.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-09-23.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-09-30.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-10-07.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-06-03.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-06-10.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-06-17.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-06-24.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-07-01.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-07-08.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-07-15.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-07-22.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-07-29.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-08-05.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-08-12.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-08-19.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-08-26.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-09-02.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-09-09.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-09-16.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-09-23.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-09-30.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-10-07.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-06-03.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-06-10.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-06-17.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-06-24.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-07-01.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-07-08.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-07-15.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-07-22.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-07-29.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-08-05.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-08-12.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-08-19.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-08-26.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-09-02.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-09-09.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-09-16.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-09-23.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-09-30.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-10-07.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-06-03.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-06-10.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-06-17.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-06-24.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-07-01.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-07-08.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-07-15.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-07-22.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-07-29.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-08-05.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-08-12.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-08-19.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-08-26.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-09-02.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-09-09.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-09-16.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-09-23.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-09-30.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-10-07.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-10-14.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-10-21.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-10-28.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-11-04.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-11-11.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-11-18.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-11-25.pq'\n"
     ]
    }
   ],
   "source": [
    "# put all forecasts into one dataframe\n",
    "predictionsall = pd.DataFrame()\n",
    "for model in models:\n",
    "    for date in dates:\n",
    "        try:\n",
    "            predictions = pd.read_parquet(f'./dat/{model}_{date}.pq')\n",
    "            predictions['Model'] = model\n",
    "            predictionsall = pd.concat([predictionsall, predictions])\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "becaa833-2311-4a09-b131-839785ad75dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format forecasts in order to calculate scores\n",
    "# input start and end weeks for the period of interest\n",
    "test = Forecast_Eval(df=pd.DataFrame(), obsdf=surv, target='hosp', \n",
    "                            start_week = Week(2023,40), end_week = Week(2024, 17))\n",
    "predsall = test.format_forecasts_all( dfformat = predictionsall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0ef5754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_date</th>\n",
       "      <th>target</th>\n",
       "      <th>horizon</th>\n",
       "      <th>target_end_date</th>\n",
       "      <th>location</th>\n",
       "      <th>output_type</th>\n",
       "      <th>output_type_id</th>\n",
       "      <th>value</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>wk inc flu hosp</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>01</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.010</td>\n",
       "      <td>33.000</td>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>wk inc flu hosp</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-02-17</td>\n",
       "      <td>01</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.010</td>\n",
       "      <td>8.000</td>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>wk inc flu hosp</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>01</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000</td>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>wk inc flu hosp</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-03-02</td>\n",
       "      <td>01</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>wk inc flu hosp</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>01</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.025</td>\n",
       "      <td>38.000</td>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5975</th>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>wk inc flu hosp</td>\n",
       "      <td>-1</td>\n",
       "      <td>2024-01-27</td>\n",
       "      <td>56</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.990</td>\n",
       "      <td>51.115</td>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>wk inc flu hosp</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>56</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.990</td>\n",
       "      <td>45.565</td>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>wk inc flu hosp</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>56</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.990</td>\n",
       "      <td>34.377</td>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>wk inc flu hosp</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-02-17</td>\n",
       "      <td>56</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.990</td>\n",
       "      <td>27.066</td>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>wk inc flu hosp</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>56</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.990</td>\n",
       "      <td>20.553</td>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>936146 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     reference_date           target  horizon target_end_date location  \\\n",
       "0        2024-02-10  wk inc flu hosp        0      2024-02-10       01   \n",
       "1        2024-02-10  wk inc flu hosp        1      2024-02-17       01   \n",
       "2        2024-02-10  wk inc flu hosp        2      2024-02-24       01   \n",
       "3        2024-02-10  wk inc flu hosp        3      2024-03-02       01   \n",
       "4        2024-02-10  wk inc flu hosp        0      2024-02-10       01   \n",
       "...             ...              ...      ...             ...      ...   \n",
       "5975     2024-02-03  wk inc flu hosp       -1      2024-01-27       56   \n",
       "5976     2024-02-03  wk inc flu hosp        0      2024-02-03       56   \n",
       "5977     2024-02-03  wk inc flu hosp        1      2024-02-10       56   \n",
       "5978     2024-02-03  wk inc flu hosp        2      2024-02-17       56   \n",
       "5979     2024-02-03  wk inc flu hosp        3      2024-02-24       56   \n",
       "\n",
       "     output_type  output_type_id   value                  Model  \n",
       "0       quantile           0.010  33.000       CEPH-Rtrend_fluH  \n",
       "1       quantile           0.010   8.000       CEPH-Rtrend_fluH  \n",
       "2       quantile           0.010   1.000       CEPH-Rtrend_fluH  \n",
       "3       quantile           0.010   0.000       CEPH-Rtrend_fluH  \n",
       "4       quantile           0.025  38.000       CEPH-Rtrend_fluH  \n",
       "...          ...             ...     ...                    ...  \n",
       "5975    quantile           0.990  51.115  NU_UCSD-GLEAM_AI_FLUH  \n",
       "5976    quantile           0.990  45.565  NU_UCSD-GLEAM_AI_FLUH  \n",
       "5977    quantile           0.990  34.377  NU_UCSD-GLEAM_AI_FLUH  \n",
       "5978    quantile           0.990  27.066  NU_UCSD-GLEAM_AI_FLUH  \n",
       "5979    quantile           0.990  20.553  NU_UCSD-GLEAM_AI_FLUH  \n",
       "\n",
       "[936146 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d54454-0767-45d8-a775-c464d0722da8",
   "metadata": {},
   "source": [
    "## WIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "21a5a1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwis = pd.DataFrame()\n",
    "\n",
    "for horizon in [0, 1, 2,3]:\n",
    "    for model in models:\n",
    "        for date in dates: \n",
    "            for loc in predsall.location.unique():\n",
    "                start_week = Week.fromdate(pd.to_datetime(date)) # week of submission date\n",
    "                end_week = start_week + 3 # target end date of last horizon\n",
    "\n",
    "                # filter by horizon, model and submission date\n",
    "                pred = predsall[(predsall.horizon==horizon) & (predsall.Model == model) & \\\n",
    "                                (predsall.reference_date == date) & (predsall.location==loc)]\n",
    "\n",
    "                test = Scoring(df=pred, obsdf=surv, target='hosp')\n",
    "                predss = test.process_predictions(pred, t_col = 'target_end_date', quantile_col = 'output_type_id')\n",
    "\n",
    "                if len(predss)==0:\n",
    "                    continue\n",
    "\n",
    "                obs = test.get_observations(loc)\n",
    "                obs = obs[obs.date==pred.target_end_date.unique()[0]]\n",
    "                \n",
    "                out = test.timestamp_wis(obs, predss)\n",
    "\n",
    "                dfwis = pd.concat([dfwis, out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0033cdb-02d3-42b0-827e-91b2b1deab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwis.to_csv('./WIS.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62511981-fcf7-4312-a1de-3462e99d9e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>location</th>\n",
       "      <th>horizon</th>\n",
       "      <th>reference_date</th>\n",
       "      <th>target_end_date</th>\n",
       "      <th>wis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>23.486087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>02</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>1.552011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>04</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>18.480870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>05</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>68.074783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>72.717617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>18.293802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>81.821324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>128.840227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>15.025052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>US</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>4179.024134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33232 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model location  horizon reference_date target_end_date  \\\n",
       "0        CEPH-Rtrend_fluH       01        0     2024-02-10      2024-02-10   \n",
       "0        CEPH-Rtrend_fluH       02        0     2024-02-10      2024-02-10   \n",
       "0        CEPH-Rtrend_fluH       04        0     2024-02-10      2024-02-10   \n",
       "0        CEPH-Rtrend_fluH       05        0     2024-02-10      2024-02-10   \n",
       "0        CEPH-Rtrend_fluH       06        0     2024-02-10      2024-02-10   \n",
       "..                    ...      ...      ...            ...             ...   \n",
       "0   NU_UCSD-GLEAM_AI_FLUH       53        3     2024-02-03      2024-02-24   \n",
       "0   NU_UCSD-GLEAM_AI_FLUH       54        3     2024-02-03      2024-02-24   \n",
       "0   NU_UCSD-GLEAM_AI_FLUH       55        3     2024-02-03      2024-02-24   \n",
       "0   NU_UCSD-GLEAM_AI_FLUH       56        3     2024-02-03      2024-02-24   \n",
       "0   NU_UCSD-GLEAM_AI_FLUH       US        3     2024-02-03      2024-02-24   \n",
       "\n",
       "            wis  \n",
       "0     23.486087  \n",
       "0      1.552011  \n",
       "0     18.480870  \n",
       "0     68.074783  \n",
       "0     72.717617  \n",
       "..          ...  \n",
       "0     18.293802  \n",
       "0     81.821324  \n",
       "0    128.840227  \n",
       "0     15.025052  \n",
       "0   4179.024134  \n",
       "\n",
       "[33232 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ee3316-8513-4a97-ae00-623d05d0b606",
   "metadata": {},
   "source": [
    "## WIS Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7bdaa32c-25c0-413c-9f48-51a354682ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute wis ratio, comparing the Flusight models' forecast scores to the Flusight baseline model\n",
    "# divide flusight models by flusight baseline WIS scores at each location, week, horizon, location\n",
    "dfwis = pd.read_csv('./WIS.csv')\n",
    "baseline = dfwis[dfwis.Model == 'FluSight-baseline'] \n",
    "baseline = baseline.rename(columns={'wis':'wis_baseline', 'Model':'baseline'})\n",
    "dfwis_test = dfwis[dfwis.Model != 'FluSight-baseline']\n",
    "\n",
    "dfwis_ratio = pd.merge(dfwis_test, baseline, how='inner', on = ['location', 'target_end_date',\n",
    "                                                                'horizon', 'reference_date'])\n",
    "\n",
    "# calculate wis ratio\n",
    "dfwis_ratio['wis_ratio'] = dfwis_ratio['wis']/dfwis_ratio['wis_baseline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ef766a4-de11-465c-8188-7bff9402806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwis_ratio.to_csv('./WIS_ratio.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3e13e46d-a6ef-4f18-8c0f-258cb38409e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>location</th>\n",
       "      <th>horizon</th>\n",
       "      <th>reference_date</th>\n",
       "      <th>target_end_date</th>\n",
       "      <th>wis</th>\n",
       "      <th>baseline</th>\n",
       "      <th>wis_baseline</th>\n",
       "      <th>wis_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>23.486087</td>\n",
       "      <td>FluSight-baseline</td>\n",
       "      <td>4.426771</td>\n",
       "      <td>5.305467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>02</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>1.552011</td>\n",
       "      <td>FluSight-baseline</td>\n",
       "      <td>2.349696</td>\n",
       "      <td>0.660516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>04</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>18.480870</td>\n",
       "      <td>FluSight-baseline</td>\n",
       "      <td>129.095261</td>\n",
       "      <td>0.143157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>05</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>68.074783</td>\n",
       "      <td>FluSight-baseline</td>\n",
       "      <td>28.809460</td>\n",
       "      <td>2.362932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>72.717617</td>\n",
       "      <td>FluSight-baseline</td>\n",
       "      <td>36.713068</td>\n",
       "      <td>1.980701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27397</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>18.293802</td>\n",
       "      <td>FluSight-baseline</td>\n",
       "      <td>15.104333</td>\n",
       "      <td>1.211163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27398</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>81.821324</td>\n",
       "      <td>FluSight-baseline</td>\n",
       "      <td>15.614839</td>\n",
       "      <td>5.239972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27399</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>128.840227</td>\n",
       "      <td>FluSight-baseline</td>\n",
       "      <td>44.581886</td>\n",
       "      <td>2.889968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27400</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>15.025052</td>\n",
       "      <td>FluSight-baseline</td>\n",
       "      <td>7.647149</td>\n",
       "      <td>1.964791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27401</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>US</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>4179.024134</td>\n",
       "      <td>FluSight-baseline</td>\n",
       "      <td>886.529621</td>\n",
       "      <td>4.713914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27402 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model location  horizon reference_date target_end_date  \\\n",
       "0           CEPH-Rtrend_fluH       01        0     2024-02-10      2024-02-10   \n",
       "1           CEPH-Rtrend_fluH       02        0     2024-02-10      2024-02-10   \n",
       "2           CEPH-Rtrend_fluH       04        0     2024-02-10      2024-02-10   \n",
       "3           CEPH-Rtrend_fluH       05        0     2024-02-10      2024-02-10   \n",
       "4           CEPH-Rtrend_fluH       06        0     2024-02-10      2024-02-10   \n",
       "...                      ...      ...      ...            ...             ...   \n",
       "27397  NU_UCSD-GLEAM_AI_FLUH       53        3     2024-02-03      2024-02-24   \n",
       "27398  NU_UCSD-GLEAM_AI_FLUH       54        3     2024-02-03      2024-02-24   \n",
       "27399  NU_UCSD-GLEAM_AI_FLUH       55        3     2024-02-03      2024-02-24   \n",
       "27400  NU_UCSD-GLEAM_AI_FLUH       56        3     2024-02-03      2024-02-24   \n",
       "27401  NU_UCSD-GLEAM_AI_FLUH       US        3     2024-02-03      2024-02-24   \n",
       "\n",
       "               wis           baseline  wis_baseline  wis_ratio  \n",
       "0        23.486087  FluSight-baseline      4.426771   5.305467  \n",
       "1         1.552011  FluSight-baseline      2.349696   0.660516  \n",
       "2        18.480870  FluSight-baseline    129.095261   0.143157  \n",
       "3        68.074783  FluSight-baseline     28.809460   2.362932  \n",
       "4        72.717617  FluSight-baseline     36.713068   1.980701  \n",
       "...            ...                ...           ...        ...  \n",
       "27397    18.293802  FluSight-baseline     15.104333   1.211163  \n",
       "27398    81.821324  FluSight-baseline     15.614839   5.239972  \n",
       "27399   128.840227  FluSight-baseline     44.581886   2.889968  \n",
       "27400    15.025052  FluSight-baseline      7.647149   1.964791  \n",
       "27401  4179.024134  FluSight-baseline    886.529621   4.713914  \n",
       "\n",
       "[27402 rows x 9 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwis_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9210ecf5-de59-4228-a65d-ba10ba3c9962",
   "metadata": {},
   "source": [
    "## Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1f2470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcoverage = pd.DataFrame()\n",
    "\n",
    "for date in dates:\n",
    "    for model in models:\n",
    "        for loc in predsall.location.unique():\n",
    "            for horizon in [0,1,2,3]:\n",
    "                start_week = Week.fromdate(pd.to_datetime(date)) # week of submission date\n",
    "                end_week = start_week + 3 # target end date of last horizon\n",
    "\n",
    "                # filter by model and submission date, only look at horizon 0-3\n",
    "                pred = predsall[(predsall.Model == model)& (predsall.reference_date == date) &\\\n",
    "                                (predsall.horizon ==horizon) & (predsall.location==loc)]\n",
    "\n",
    "                if len(pred)==0:\n",
    "                    continue\n",
    "\n",
    "                test = Scoring(df=pred, obsdf=surv, target='hosp')\n",
    "                predss = test.process_predictions(pred, t_col = 'target_end_date', quantile_col = 'output_type_id')\n",
    "\n",
    "\n",
    "                obs = test.get_observations(loc)\n",
    "                obs = obs[obs.date.isin(pred.target_end_date.unique())]\n",
    "\n",
    "                out = test.all_coverages_from_df(obs, predss)\n",
    "\n",
    "                out['horizon'] = horizon\n",
    "                out['Model'] = model\n",
    "                out['reference_date'] = date\n",
    "                out['location'] = loc\n",
    "\n",
    "                dfcoverage = pd.concat([dfcoverage, pd.DataFrame(out,index=[0])])\n",
    "dfcoverage = dfcoverage.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d2e5ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10_cov</th>\n",
       "      <th>20_cov</th>\n",
       "      <th>30_cov</th>\n",
       "      <th>40_cov</th>\n",
       "      <th>50_cov</th>\n",
       "      <th>60_cov</th>\n",
       "      <th>70_cov</th>\n",
       "      <th>80_cov</th>\n",
       "      <th>90_cov</th>\n",
       "      <th>95_cov</th>\n",
       "      <th>98_cov</th>\n",
       "      <th>horizon</th>\n",
       "      <th>Model</th>\n",
       "      <th>reference_date</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33227</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33228</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33229</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33230</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33231</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33232 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       10_cov  20_cov  30_cov  40_cov  50_cov  60_cov  70_cov  80_cov  90_cov  \\\n",
       "0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0   \n",
       "3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4         1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "33227     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "33228     0.0     0.0     0.0     0.0     0.0     1.0     1.0     1.0     1.0   \n",
       "33229     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0   \n",
       "33230     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "33231     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       95_cov  98_cov  horizon                  Model reference_date location  \n",
       "0         1.0     1.0        0       CEPH-Rtrend_fluH     2024-02-10       01  \n",
       "1         0.0     1.0        1       CEPH-Rtrend_fluH     2024-02-10       01  \n",
       "2         1.0     1.0        2       CEPH-Rtrend_fluH     2024-02-10       01  \n",
       "3         1.0     1.0        3       CEPH-Rtrend_fluH     2024-02-10       01  \n",
       "4         1.0     1.0        0       CEPH-Rtrend_fluH     2024-02-10       02  \n",
       "...       ...     ...      ...                    ...            ...      ...  \n",
       "33227     0.0     0.0        3  NU_UCSD-GLEAM_AI_FLUH     2024-02-03       56  \n",
       "33228     1.0     1.0        0  NU_UCSD-GLEAM_AI_FLUH     2024-02-03       US  \n",
       "33229     1.0     1.0        1  NU_UCSD-GLEAM_AI_FLUH     2024-02-03       US  \n",
       "33230     1.0     1.0        2  NU_UCSD-GLEAM_AI_FLUH     2024-02-03       US  \n",
       "33231     0.0     1.0        3  NU_UCSD-GLEAM_AI_FLUH     2024-02-03       US  \n",
       "\n",
       "[33232 rows x 15 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcoverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e655b66-10f5-436a-b87e-f91e681ad909",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcoverage.to_csv('./coverage.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bab22c",
   "metadata": {},
   "source": [
    "# MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed5fb010",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate MAPE for all forecasts\n",
    "\n",
    "dfmape = pd.DataFrame()\n",
    "\n",
    "for horizon in [0, 1, 2,3]:\n",
    "    for model in models:\n",
    "        for date in dates: \n",
    "            start_week = Week.fromdate(pd.to_datetime(date)) # week of submission date\n",
    "            end_week = start_week + 3 # target end date of last horizon\n",
    "            \n",
    "            # filter by horizon, model and submission date\n",
    "            pred = predsall[(predsall.horizon==horizon) & (predsall.Model == model) & \\\n",
    "                            (predsall.reference_date == date)]\n",
    "            if len(pred)==0:\n",
    "                continue\n",
    "            \n",
    "            # calculate mape for each week\n",
    "            test = Scoring(df=pred, obsdf=surv, target='hosp',\n",
    "                            start_week = start_week, end_week = end_week)\n",
    "\n",
    "            out = test.get_mape()\n",
    "            \n",
    "            out['horizon'] = horizon\n",
    "            out['reference_date'] = date\n",
    "            \n",
    "            dfmape = pd.concat([dfmape, out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb310c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmape.to_csv('./MAPE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42c04295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Location</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>horizon</th>\n",
       "      <th>reference_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>01</td>\n",
       "      <td>0.357798</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>02</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>04</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>05</td>\n",
       "      <td>0.329897</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>06</td>\n",
       "      <td>0.265086</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>50</td>\n",
       "      <td>0.480269</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>53</td>\n",
       "      <td>0.367763</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>55</td>\n",
       "      <td>0.733366</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>54</td>\n",
       "      <td>0.643914</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>56</td>\n",
       "      <td>0.711481</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32582 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model Location      MAPE  horizon reference_date\n",
       "0        CEPH-Rtrend_fluH       01  0.357798        0     2024-02-10\n",
       "1        CEPH-Rtrend_fluH       02  0.090909        0     2024-02-10\n",
       "2        CEPH-Rtrend_fluH       04  0.131148        0     2024-02-10\n",
       "3        CEPH-Rtrend_fluH       05  0.329897        0     2024-02-10\n",
       "4        CEPH-Rtrend_fluH       06  0.265086        0     2024-02-10\n",
       "..                    ...      ...       ...      ...            ...\n",
       "47  NU_UCSD-GLEAM_AI_FLUH       50  0.480269        3     2024-02-03\n",
       "48  NU_UCSD-GLEAM_AI_FLUH       53  0.367763        3     2024-02-03\n",
       "49  NU_UCSD-GLEAM_AI_FLUH       55  0.733366        3     2024-02-03\n",
       "50  NU_UCSD-GLEAM_AI_FLUH       54  0.643914        3     2024-02-03\n",
       "51  NU_UCSD-GLEAM_AI_FLUH       56  0.711481        3     2024-02-03\n",
       "\n",
       "[32582 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f72c73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
