{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53044182-bf0b-4dcd-b811-eee167b40de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from scorepi import *\n",
    "from epiweeks import Week\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9f67dd-2b72-4f6f-bad4-584da6ada67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.9\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98848f4d-50db-457e-94cf-aaf8d913e35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b21d823-76a1-420b-a2ef-dd7b8318c14f",
   "metadata": {},
   "source": [
    "Python and pandas versions must be enforced for this code to work. There is a copying error which occurs in the scorepi class constructors when using newer versions.\n",
    "\n",
    "# Load Data\n",
    "\n",
    "At least for now, I'm using Clara's functions for pulling predictions and surveillance data. We will probably want to set up the Flusight repo as a submodule and pull new data on a schedule. \n",
    "\n",
    "\n",
    "Here's how it's currently implemented:\n",
    "1. For each selected model and date, we save each forecast submission as-is in parquet format.\n",
    "2. For each selected model and date, we read the corresponding parquets and concatenate into a single data frame.\n",
    "3. We instantiate the Forecast_Eval class with a given start and end week, and call the format_forecasts_all method on the concatenated predictions dataframe, which filters for quantile predictions, removes dates after the end week, enforces datatypes, and returns the formatted dataframe to be used in scoring. (NOTE: start week is not used, what's up with that?)\n",
    "\n",
    "Automating this workflow will probably involve:\n",
    "1. Calculate scorings for all historical data once and save.\n",
    "2. Set up the Flusight repo as a submodule and pull new data on a schedule.\n",
    "3. It might be possible to keep the implementation with parquets if github can run it (pulling from flusight repo and writing and reading parquets within a python script). This would eliminate (2.) and could avoid problems when making epistorm-evaluations a submodule of epistorm-dashboard, since it also has the flusight repo as a submodule.\n",
    "4. Every time new data is pulled, calculate scoring for only the new data and append to existing scoring files. Do we need to re-calculate scores for previous weeks in case surveillance data changes retrospectively?\n",
    "5. We might generate separate files with transformed data for charts in the dashboard, if so either:\n",
    "    1. Do that here, add epistorm-evaluations as a submodule of epistorm-dashboard, and pull the transformed scores on a schedule.\n",
    "    2. Add epistorm-evaluations as a submodule of epistorm-dashboard, pull the scoring files on a schedule, and trigger a script within epistorm-dashboard to create the transformed scoring files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b823c2e-43ad-4f25-9ec2-68864e3cffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to download flusight model predictions and surveillance data\n",
    "\n",
    "def pull_flusight_predictions(model,date):\n",
    "    \"\"\"pull_flusight_predictions. Load predictions of the model saved by the Flusight Forecast hub\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : str\n",
    "        Model name on the\n",
    "    dates : list or string\n",
    "        List of potential dates in the iso format, e.g., 'yyyy-mm-dd', for the submission.\n",
    "    \"\"\"\n",
    "    predictions = None\n",
    "    \n",
    "    url = f\"https://raw.githubusercontent.com/cdcepi/Flusight-forecast-hub/main/model-output/{model}/{date}-{model}\"\n",
    "    for ext in [\".csv\",\".gz\",\".zip\",\".csv.zip\",\".csv.gz\"]:\n",
    "        try:\n",
    "            predictions = pd.read_csv(url+ext,dtype={'location':str},parse_dates=['target_end_date'])\n",
    "        except:\n",
    "            pass\n",
    "    if predictions is None:\n",
    "        print(f\"Data for model {model} and date {date} unavailable\")\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def pull_surveillance_data():\n",
    "    \"\"\"pull_surveillance_data. Load hospitalization admissions surveillance data\n",
    "    \"\"\"\n",
    "    \n",
    "    url = f\"https://raw.githubusercontent.com/cdcepi/FluSight-forecast-hub/main/target-data/target-hospital-admissions.csv\"\n",
    "    return pd.read_csv(url, dtype={'location':str})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cd36fa6-150b-47d2-8ce7-3e82281b708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and save surveillance data\n",
    "surv = pull_surveillance_data() \n",
    "surv = surv[surv.date >= '2023-06-01'] # filtered dates after june 2023 since we are only looking at 2023-24 season\n",
    "surv.to_parquet(f\"./dat/target-hospital-admissions.pq\", index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "745b3b96-e522-432b-aac2-b5ecdabd539f",
   "metadata": {},
   "source": [
    "### From Clara's notebook\n",
    "# download and save forecasts for specified submission week (date) and for specified models from flusight github\n",
    "\n",
    "dates = [ '2024-04-06', '2024-04-13', '2024-04-20', '2024-04-27']\n",
    "\n",
    "models = ['CADPH-FluCAT_Ensemble', 'CEPH-Rtrend_fluH',  'CMU-TimeSeries', 'CU-ensemble', 'FluSight-baseline',\n",
    "          'FluSight-ensemble','FluSight-equal_cat', 'FluSight-lop_norm', 'GH-model', 'GT-FluFNP', 'ISU_NiemiLab-ENS', \n",
    "          'ISU_NiemiLab-NLH','ISU_NiemiLab-SIR', 'LUcompUncertLab-chimera', 'LosAlamos_NAU-CModel_Flu', \n",
    "          'MIGHTE-Nsemble','MOBS-GLEAM_FLUH', 'NIH-Flu_ARIMA', 'PSI-PROF', 'SGroup-RandomForest', 'SigSci-CREG', \n",
    "          'SigSci-TSENS','Stevens-GBR', 'UGA_flucast-Copycat', 'UGA_flucast-INFLAenza', 'UGA_flucast-OKeeffe', \n",
    "          'UGuelph-CompositeCurve', 'UGuelphensemble-GRYPHON', 'UM-DeepOutbreak', 'UMass-flusion', \n",
    "          'UMass-trends_ensemble', 'UNC_IDD-InfluPaint', 'UVAFluX-Ensemble', 'VTSanghani-Ensemble', 'cfa-flumech',\n",
    "          'cfarenewal-cfaepimlight', 'fjordhest-ensemble', 'NU_UCSD-GLEAM_AI_FLUH', 'PSI-PROF_beta',\n",
    "          'JHU_CSSE-CSSE_Ensemble', 'FluSight-national_cat', 'FluSight-ens_q_cat', 'FluSight-baseline_cat']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce7163e-f762-47c3-b3a4-e6a7f322f9bf",
   "metadata": {},
   "source": [
    "Clara was hard-coding dates to pull each time she manually ran this notebook. Since we want scores for all historical data, I'm using all dates from the surveillance file. I don't think this should cause a bug or miss any data but it would be good to have a second opinion.\n",
    "\n",
    "Once we've got all the historical scores, if we're only scoring new predictions every week, should we only use the most recent surveillance date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2055db05-7fe1-4a76-ae2f-1a1e0a2c8cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting all target dates that exist in the surveillance file\n",
    "dates = pd.unique(surv.date)\n",
    "\n",
    "#selecting just models used in the dashboard for now\n",
    "#will need to expand eventually whether we keep the parquet implementation or pull files from the flusight repo as a submodule\n",
    "models = ['CEPH-Rtrend_fluH', 'FluSight-baseline', 'FluSight-ensemble', 'MIGHTE-Nsemble', 'MOBS-GLEAM_FLUH', 'NU_UCSD-GLEAM_AI_FLUH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6805cfdd-aac5-42e7-9d38-74097fafc0c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for model CEPH-Rtrend_fluH and date 2023-10-07 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-09-30 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-09-23 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-09-16 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-09-09 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-09-02 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-08-26 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-08-19 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-08-12 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-08-05 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-07-29 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-07-22 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-07-15 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-07-08 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-07-01 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-06-24 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-06-17 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-06-10 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model CEPH-Rtrend_fluH and date 2023-06-03 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-10-07 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-09-30 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-09-23 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-09-16 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-09-09 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-09-02 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-08-26 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-08-19 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-08-12 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-08-05 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-07-29 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-07-22 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-07-15 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-07-08 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-07-01 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-06-24 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-06-17 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-06-10 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-baseline and date 2023-06-03 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-10-07 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-09-30 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-09-23 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-09-16 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-09-09 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-09-02 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-08-26 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-08-19 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-08-12 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-08-05 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-07-29 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-07-22 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-07-15 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-07-08 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-07-01 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-06-24 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-06-17 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-06-10 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model FluSight-ensemble and date 2023-06-03 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-10-07 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-09-30 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-09-23 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-09-16 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-09-09 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-09-02 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-08-26 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-08-19 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-08-12 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-08-05 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-07-29 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-07-22 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-07-15 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-07-08 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-07-01 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-06-24 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-06-17 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for model MIGHTE-Nsemble and date 2023-06-10 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MIGHTE-Nsemble and date 2023-06-03 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-10-07 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-09-30 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-09-23 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-09-16 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-09-09 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-09-02 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-08-26 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-08-19 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-08-12 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-08-05 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-07-29 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-07-22 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-07-15 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-07-08 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-07-01 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-06-24 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-06-17 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-06-10 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model MOBS-GLEAM_FLUH and date 2023-06-03 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-11-25 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-11-18 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-11-11 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-11-04 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-10-28 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-10-21 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-10-14 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-10-07 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-09-30 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-09-23 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-09-16 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-09-09 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-09-02 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-08-26 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-08-19 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-08-12 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-08-05 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-07-29 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-07-22 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-07-15 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-07-08 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-07-01 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-06-24 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-06-17 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-06-10 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n",
      "Data for model NU_UCSD-GLEAM_AI_FLUH and date 2023-06-03 unavailable\n",
      "'NoneType' object has no attribute 'to_parquet'\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    for date in dates:\n",
    "        try:\n",
    "            predictions = pull_flusight_predictions(model,date)\n",
    "\n",
    "            predictions.to_parquet(f'./dat/{model}_{date}.pq', index=False)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ebbec-69bc-4dbf-973f-048728983389",
   "metadata": {},
   "source": [
    "# Classes and Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b66a9f77-bc14-430c-bd38-cfaa2218054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for calculating scores of the forecasts against the surveillance data\n",
    "\n",
    "class Forecast_Eval:\n",
    "    \"\"\" Used for scoring and evaluating flu forecasting predictions from the Flusight challenge for the \n",
    "        2023-24 season\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, obsdf, target,  start_week = False, end_week = False):\n",
    "        self.df = df # pandas Dataframe: input dataframe of forecasts with all scenarios, locations, and quantiles\n",
    "        self.obsdf = obsdf # pandas Dataframe: input of surveillance data of interest\n",
    "        self.target = target # str: target metric of interest (case, death, hospitalization)\n",
    "        self.start_week = start_week # epiweek: beginning of observations of interest\n",
    "        self.end_week = end_week # epiweek: end of observations of interest\n",
    "        \n",
    "          \n",
    "    def get_observations(self, target_location):\n",
    "        \"\"\" get_observations. Load and filter surveillance data for a certain location.\n",
    "        Parameters\n",
    "        ----------\n",
    "        target_location : str\n",
    "            location to filter surveillance data by\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.target == 'hosp':\n",
    "            target_obs = 'hospitalization'\n",
    "        else:\n",
    "            target_obs = self.target\n",
    "            \n",
    "        # read in observations dataframe\n",
    "        observations = self.obsdf.copy().drop(columns= ['Unnamed: 0', 'weekly_rate'])\n",
    "        observations['date'] = pd.to_datetime(observations['date'])\n",
    "\n",
    "        #filter start - end week\n",
    "        if self.start_week:\n",
    "            observations = observations[(observations['date'] >= pd.to_datetime(self.start_week.startdate())) ]\n",
    "            \n",
    "        if self.end_week:\n",
    "            observations = observations[(observations['date'] <= pd.to_datetime(self.end_week.enddate()))]\n",
    "                                \n",
    "        #filter location\n",
    "        observations = observations[observations['location'] == target_location]\n",
    "\n",
    "        #aggregate to weekly\n",
    "        observations = observations.groupby(['location', pd.Grouper(key='date', freq='W-SAT')]).sum().reset_index()\n",
    "\n",
    "        #transform to Observation object\n",
    "        observations = Observations(observations)\n",
    "\n",
    "        return observations\n",
    "    \n",
    "    \n",
    "    def format_forecasts_all(self, dfformat):\n",
    "        \"\"\" format_forecasts_all. Get forecasts into standard format to use for scoring.\n",
    "        Parameters\n",
    "        ----------\n",
    "        dfformat : pandas DataFrame\n",
    "            dataframe of forecast output used for formatting\n",
    "        \"\"\"\n",
    "        \n",
    "        pred = dfformat.copy()\n",
    "        pred = pred[pred.output_type == 'quantile'] # only keep quantile predictions\n",
    "        pred['target_end_date'] = pd.to_datetime(pred['target_end_date']) #make sure dates are in datetime format\n",
    "        if self.start_week:\n",
    "            pred = pred[(pred['target_end_date'] >= pd.to_datetime(self.start_week.startdate()))] # filter dates\n",
    "        \n",
    "        if self.end_week:\n",
    "            pred = pred[(pred['target_end_date'] <= pd.to_datetime(self.end_week.enddate()))] # filter dates\n",
    "        \n",
    "        pred['output_type_id'] = pred[\"output_type_id\"].astype(float) # make sure quantile levels are floats\n",
    "        \n",
    "        return pred\n",
    "        \n",
    "    \n",
    "\n",
    "class Scoring(Forecast_Eval):\n",
    "    \"\"\" calculate score values for probabilistic epidemic forecasts \n",
    "    find WIS, MAPE, and coverage over whole projection window as well as timestamped for every week.\n",
    "    uses scorepi package to calculate the scores  (https://github.com/gstonge/scorepi/tree/main)\n",
    "    score dataframe must have 'Model' column to differentiate and calculate scores for different models\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, obsdf, target, start_week = False, \n",
    "                 end_week = False):\n",
    "        super().__init__(df, obsdf, target, start_week, end_week)\n",
    "        \n",
    "    def get_all_average_scores(self, models):\n",
    "        \"\"\" get_all_average_scores. Calculate all score in scorepi package that average over the full forecast\n",
    "        time series. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        models: list\n",
    "            list of models that the scores will be calculated for, each element is a string corresponding to\n",
    "            a forecast model's name from the Model column of the forecast dataframe\n",
    "        \"\"\"\n",
    "        \n",
    "        pred1 = self.df.copy() # dataframe that will be scored\n",
    "        loclist = list(pred1.location.unique()) \n",
    "        \n",
    "        \n",
    "        allscore = {}\n",
    "        for model in models:\n",
    "            allscore[model] = {}\n",
    "            for target_location in loclist:\n",
    "                if target_location == '72':\n",
    "                    continue\n",
    "                #print(target_location)\n",
    "                \n",
    "                observations = self.get_observations(target_location) # get surveillance data for target location \n",
    "\n",
    "                # filter by model and location\n",
    "                pred = pred1[(pred1.Model==model) & (pred1['location']==target_location) ] \n",
    "                # make into Predictions object\n",
    "                pred = Predictions(pred, t_col = 'target_end_date', quantile_col = 'output_type_id')\n",
    "                observations = Observations(observations[observations.date<=pred.target_end_date.max()])\n",
    "                #calculate scores\n",
    "                d,_ = score_utils.all_scores_from_df(observations, pred, mismatched_allowed=False) \n",
    "\n",
    "                # save in dictionary\n",
    "                allscore[model][target_location] = d\n",
    "            \n",
    "        \n",
    "        return allscore\n",
    "    \n",
    "    def organize_average_scores(self, want_scores, models):\n",
    "        \"\"\" organize_average_scores. save average scores of interest into a pandas dataframe\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        want_scores: list\n",
    "            list of scores you want to save in the dataframe\n",
    "            wis is 'wis_mean', and all coverages are '10_cov', '20_cov', ... '95_cov' etc.\n",
    "        models: list\n",
    "            list of models that the scores will be calculated for, each element is a string correspongding to\n",
    "            a forecast model's name from the Model column of the forecast dataframe. \n",
    "            used for get_all_average_scores function call.\n",
    "        \"\"\"\n",
    "        \n",
    "        average_scores = pd.DataFrame()\n",
    "        \n",
    "        allscore = self.get_all_average_scores(models) #calculate all average scores\n",
    "        \n",
    "        for model in allscore.keys():\n",
    "            scoresmod = allscore[model]\n",
    "            for loc in scoresmod.keys():\n",
    "                    \n",
    "                scoresloc = scoresmod[loc]\n",
    "\n",
    "                scoredict = {'Model': model ,'location': loc}\n",
    "                for score in want_scores: # only save scores input into want_scores\n",
    "                    scoredict[score] = scoresloc[score]\n",
    "\n",
    "                average_scores = pd.concat([average_scores, pd.DataFrame(scoredict, index=[0])])\n",
    "\n",
    "        average_scores = average_scores.reset_index() \n",
    "        average_scores = average_scores.drop(columns=['index'])\n",
    "        \n",
    "        return average_scores\n",
    "    \n",
    "    def get_all_timestamped_scores(self, models):\n",
    "        \"\"\" get_all_timestamped_scores. Calculate all scores in scorepi package for each week of the full forecast\n",
    "        time series. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        models: list\n",
    "            list of models that the scores will be calculated for, each element is a string corresponding to\n",
    "            a forecast model's name from the Model column of the forecast dataframe\n",
    "        \"\"\"\n",
    "        \n",
    "        pred = self.df.copy() # dataframe used for scoring\n",
    "        loclist = list(pred.location.unique())\n",
    "        \n",
    "        allscore = {}\n",
    "        \n",
    "        for model in models:\n",
    "            allscore[model] = {}\n",
    "            for target_location in loclist:\n",
    "                    \n",
    "                observations = self.get_observations(target_location) # get surveillance data for target location\n",
    "                \n",
    "                try:\n",
    "                    predss = pred[pred['location'] == target_location] #filter by location\n",
    "                    # format forecasts into Predictions scorepi objec\n",
    "                    predss = Predictions(predss, t_col = 'target_end_date', quantile_col = 'output_type_id')\n",
    "                    \n",
    "                    if len(predss)==0:\n",
    "                        continue\n",
    "                    \n",
    "                    allscore[model][target_location] = {}\n",
    "                    # loop over all time points in the predictions\n",
    "                    for t in predss.target_end_date.unique():\n",
    "                        prednew = predss[predss.target_end_date == t]\n",
    "                        obsnew = observations[observations.date == t]\n",
    "\n",
    "                        obsnew = Observations(obsnew)\n",
    "                        prednew = Predictions(prednew, t_col = 'target_end_date', quantile_col = 'output_type_id')\n",
    "\n",
    "                        # calculate scores\n",
    "                        d = score_utils.all_timestamped_scores_from_df(obsnew, prednew)\n",
    "\n",
    "                        allscore[model][target_location][t] = d\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "        \n",
    "        return allscore\n",
    "    \n",
    "    \n",
    "    def organize_timestamped_scores(self, want_scores, models):\n",
    "        \"\"\" organize_timestamped_scores. save timestamped scores of interest into a pandas dataframe\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        want_scores: list\n",
    "            list of scores you want to save in the dataframe\n",
    "            wis is 'wis'\n",
    "        models: list\n",
    "            list of models that the scores will be calculated for, each element is a string correspongding to\n",
    "            a forecast model's name from the Model column of the forecast dataframe. \n",
    "            used for get_all_timestamped_scores function call.\n",
    "        \"\"\"\n",
    "    \n",
    "        \n",
    "        time_scores = pd.DataFrame()\n",
    "        \n",
    "        # calculate all scores evaluated for each time point\n",
    "        allscore = self.get_all_timestamped_scores(models=models)\n",
    "        \n",
    "        for model in allscore.keys():\n",
    "            scoremod = allscore[model]\n",
    "        \n",
    "            for loc in scoremod.keys():\n",
    "                    \n",
    "                scoresloc = scoremod[loc]\n",
    "\n",
    "                for t in scoresloc.keys():\n",
    "                    tdf = scoresloc[t]\n",
    "\n",
    "                    scoredict = {'Model':model ,'location':loc, 'target_end_date':t}\n",
    "                    for score in want_scores:\n",
    "                        scoredict[score] = tdf[score]\n",
    "\n",
    "                    # save scores in want_scores into a dataframe\n",
    "                    time_scores = pd.concat([time_scores, pd.DataFrame(scoredict, index=[0])])\n",
    "\n",
    "        \n",
    "        time_scores = time_scores.reset_index() \n",
    "        time_scores = time_scores.drop(columns=['index'])\n",
    "        \n",
    "        return time_scores\n",
    "    \n",
    "    \n",
    "    def get_mape(self):\n",
    "        \"\"\" get_mape. Calculate MAPE (mean absolute percentage error) for each date of a forecast. If \n",
    "            surveillance data point is equal to zero, the score is undefined (Nan).\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        predictions = self.df.copy()\n",
    "        \n",
    "        # get point forecast, here we say it is the median\n",
    "        predictions = predictions[predictions['output_type_id'] == 0.5] # get point forecast, here we say it is the median\n",
    "\n",
    "        mapedf = pd.DataFrame()\n",
    "\n",
    "        # find mape for a given model and location over projection period\n",
    "        for model in predictions.Model.unique():\n",
    "            for target_location in predictions.location.unique():\n",
    "\n",
    "                    if target_location in ['60','66','69', '72', '78']:\n",
    "                        continue\n",
    "\n",
    "                    observations = self.get_observations(target_location)\n",
    "                    \n",
    "\n",
    "                    pred = predictions[(predictions.location == target_location) & (predictions.Model==model)]\n",
    "                    pred = Predictions(pred, t_col = 'target_end_date',quantile_col='output_type_id')\n",
    "                    \n",
    "                    observations = observations[observations.date.isin(pred.target_end_date.unique())]\n",
    "\n",
    "                    n = observations.shape[0]\n",
    "\n",
    "                    realvals = list(observations.value)\n",
    "                    predvals = list(pred.value)\n",
    "\n",
    "                    \n",
    "                    if len(predvals) == 0:\n",
    "                        continue\n",
    "\n",
    "                    if realvals[0] == 0:\n",
    "                        n = n - 1\n",
    "                        continue\n",
    "\n",
    "                    err = abs((realvals[0]-predvals[0])/realvals[0]) # find relative error\n",
    "\n",
    "\n",
    "                    if n == 0:\n",
    "                        mape = None\n",
    "                    else:\n",
    "                        mape = err # calculate mape\n",
    "\n",
    "\n",
    "                    data = {'Model': model,'Location': target_location, 'MAPE':mape}\n",
    "\n",
    "                    # store in pandas DataFrame\n",
    "                    newdf = pd.DataFrame(data, index=[1])\n",
    "\n",
    "                    mapedf = pd.concat([mapedf, newdf])\n",
    "\n",
    "        mapedf = mapedf.reset_index()\n",
    "        mapedf = mapedf.drop(['index'], axis=1)\n",
    "\n",
    "        return mapedf\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dcb7f3-a01b-4daf-877a-2d5c0e427fe8",
   "metadata": {},
   "source": [
    "# Calculate Scores\n",
    "\n",
    "## Instantiate Forecast_Eval Class and Format Data for Scoring\n",
    "\n",
    "I'm keeping the dates and models specified earlier."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5cbb9bf4-811b-4a3d-8822-46b42aa32b3f",
   "metadata": {},
   "source": [
    "### From Clara's notebook\n",
    "# dates of the forecast submission dates you want to score\n",
    "#dates = [ '2024-04-06', '2024-04-13', '2024-04-20', '2024-04-27']\n",
    "\n",
    "# models you want to score\n",
    "#models = ['CADPH-FluCAT_Ensemble', 'CEPH-Rtrend_fluH',  'CMU-TimeSeries', 'CU-ensemble', 'FluSight-baseline',\n",
    "#          'FluSight-ensemble','FluSight-equal_cat', 'FluSight-lop_norm', 'GH-model', 'GT-FluFNP', 'ISU_NiemiLab-ENS', \n",
    " #         'ISU_NiemiLab-NLH','ISU_NiemiLab-SIR', 'LUcompUncertLab-chimera', 'LosAlamos_NAU-CModel_Flu', \n",
    " #         'MIGHTE-Nsemble','MOBS-GLEAM_FLUH', 'NIH-Flu_ARIMA', 'PSI-PROF', 'SGroup-RandomForest', 'SigSci-CREG', \n",
    " #         'SigSci-TSENS','Stevens-GBR', 'UGA_flucast-Copycat', 'UGA_flucast-INFLAenza', 'UGA_flucast-OKeeffe', \n",
    " #         'UGuelph-CompositeCurve', 'UGuelphensemble-GRYPHON', 'UM-DeepOutbreak', 'UMass-flusion', \n",
    " #         'UMass-trends_ensemble', 'UNC_IDD-InfluPaint', 'UVAFluX-Ensemble', 'VTSanghani-Ensemble', 'cfa-flumech',\n",
    " #         'cfarenewal-cfaepimlight', 'fjordhest-ensemble', 'NU_UCSD-GLEAM_AI_FLUH', 'PSI-PROF_beta',\n",
    " #         'JHU_CSSE-CSSE_Ensemble', 'FluSight-national_cat', 'FluSight-ens_q_cat', 'FluSight-baseline_cat']\n",
    "\n",
    "# models to score\n",
    "#models = [ 'CEPH-Rtrend_fluH', 'FluSight-baseline', 'FluSight-ensemble','MIGHTE-Nsemble','MOBS-GLEAM_FLUH', \n",
    "#          'cfarenewal-cfaepimlight', 'NU_UCSD-GLEAM_AI_FLUH', 'JHU_CSSE-CSSE_Ensemble', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc316645-5c70-4a96-ad94-ce79afeb30e2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-10-07.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-09-30.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-09-23.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-09-16.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-09-09.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-09-02.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-08-26.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-08-19.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-08-12.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-08-05.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-07-29.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-07-22.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-07-15.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-07-08.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-07-01.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-06-24.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-06-17.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-06-10.pq'\n",
      "[Errno 2] No such file or directory: './dat/CEPH-Rtrend_fluH_2023-06-03.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-10-07.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-09-30.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-09-23.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-09-16.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-09-09.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-09-02.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-08-26.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-08-19.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-08-12.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-08-05.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-07-29.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-07-22.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-07-15.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-07-08.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-07-01.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-06-24.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-06-17.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-06-10.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-baseline_2023-06-03.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-10-07.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-09-30.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-09-23.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-09-16.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-09-09.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-09-02.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-08-26.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-08-19.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-08-12.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-08-05.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-07-29.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-07-22.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-07-15.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-07-08.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-07-01.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-06-24.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-06-17.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-06-10.pq'\n",
      "[Errno 2] No such file or directory: './dat/FluSight-ensemble_2023-06-03.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-10-07.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-09-30.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-09-23.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-09-16.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-09-09.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-09-02.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-08-26.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-08-19.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-08-12.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-08-05.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-07-29.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-07-22.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-07-15.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-07-08.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-07-01.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-06-24.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-06-17.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-06-10.pq'\n",
      "[Errno 2] No such file or directory: './dat/MIGHTE-Nsemble_2023-06-03.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-10-07.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-09-30.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-09-23.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-09-16.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-09-09.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-09-02.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-08-26.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-08-19.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-08-12.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-08-05.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-07-29.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-07-22.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-07-15.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-07-08.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-07-01.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-06-24.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-06-17.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-06-10.pq'\n",
      "[Errno 2] No such file or directory: './dat/MOBS-GLEAM_FLUH_2023-06-03.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-11-25.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-11-18.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-11-11.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-11-04.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-10-28.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-10-21.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-10-14.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-10-07.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-09-30.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-09-23.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-09-16.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-09-09.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-09-02.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-08-26.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-08-19.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-08-12.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-08-05.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-07-29.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-07-22.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-07-15.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-07-08.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-07-01.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-06-24.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-06-17.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-06-10.pq'\n",
      "[Errno 2] No such file or directory: './dat/NU_UCSD-GLEAM_AI_FLUH_2023-06-03.pq'\n"
     ]
    }
   ],
   "source": [
    "# put all forecasts into one dataframe\n",
    "predictionsall = pd.DataFrame()\n",
    "for model in models:\n",
    "    for date in dates:\n",
    "        try:\n",
    "            predictions = pd.read_parquet(f'./dat/{model}_{date}.pq')\n",
    "            predictions['Model'] = model\n",
    "            predictionsall = pd.concat([predictionsall, predictions])\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "becaa833-2311-4a09-b131-839785ad75dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format forecasts in order to calculate scores\n",
    "# input start and end weeks for the period of interest\n",
    "test = Forecast_Eval(df=pd.DataFrame(), obsdf=surv, target='hosp', \n",
    "                            start_week = Week(2023,40), end_week = Week(2024, 17))\n",
    "predsall = test.format_forecasts_all( dfformat = predictionsall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9cd7c68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_date</th>\n",
       "      <th>target</th>\n",
       "      <th>horizon</th>\n",
       "      <th>target_end_date</th>\n",
       "      <th>location</th>\n",
       "      <th>output_type</th>\n",
       "      <th>output_type_id</th>\n",
       "      <th>value</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>wk inc flu hosp</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>01</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.010</td>\n",
       "      <td>3.000</td>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>wk inc flu hosp</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>01</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.025</td>\n",
       "      <td>5.000</td>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>wk inc flu hosp</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>01</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.050</td>\n",
       "      <td>7.000</td>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>wk inc flu hosp</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>01</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.100</td>\n",
       "      <td>9.000</td>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>wk inc flu hosp</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>01</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.150</td>\n",
       "      <td>10.000</td>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5975</th>\n",
       "      <td>2023-12-02</td>\n",
       "      <td>wk inc flu hosp</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-12-23</td>\n",
       "      <td>US</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.850</td>\n",
       "      <td>20509.175</td>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>2023-12-02</td>\n",
       "      <td>wk inc flu hosp</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-12-23</td>\n",
       "      <td>US</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.900</td>\n",
       "      <td>24627.713</td>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>2023-12-02</td>\n",
       "      <td>wk inc flu hosp</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-12-23</td>\n",
       "      <td>US</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.950</td>\n",
       "      <td>32274.821</td>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>2023-12-02</td>\n",
       "      <td>wk inc flu hosp</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-12-23</td>\n",
       "      <td>US</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.975</td>\n",
       "      <td>41471.763</td>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>2023-12-02</td>\n",
       "      <td>wk inc flu hosp</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-12-23</td>\n",
       "      <td>US</td>\n",
       "      <td>quantile</td>\n",
       "      <td>0.990</td>\n",
       "      <td>54137.494</td>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>936146 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     reference_date           target  horizon target_end_date location  \\\n",
       "0        2024-04-27  wk inc flu hosp        0      2024-04-27       01   \n",
       "4        2024-04-27  wk inc flu hosp        0      2024-04-27       01   \n",
       "8        2024-04-27  wk inc flu hosp        0      2024-04-27       01   \n",
       "12       2024-04-27  wk inc flu hosp        0      2024-04-27       01   \n",
       "16       2024-04-27  wk inc flu hosp        0      2024-04-27       01   \n",
       "...             ...              ...      ...             ...      ...   \n",
       "5975     2023-12-02  wk inc flu hosp        3      2023-12-23       US   \n",
       "5976     2023-12-02  wk inc flu hosp        3      2023-12-23       US   \n",
       "5977     2023-12-02  wk inc flu hosp        3      2023-12-23       US   \n",
       "5978     2023-12-02  wk inc flu hosp        3      2023-12-23       US   \n",
       "5979     2023-12-02  wk inc flu hosp        3      2023-12-23       US   \n",
       "\n",
       "     output_type  output_type_id      value                  Model  \n",
       "0       quantile           0.010      3.000       CEPH-Rtrend_fluH  \n",
       "4       quantile           0.025      5.000       CEPH-Rtrend_fluH  \n",
       "8       quantile           0.050      7.000       CEPH-Rtrend_fluH  \n",
       "12      quantile           0.100      9.000       CEPH-Rtrend_fluH  \n",
       "16      quantile           0.150     10.000       CEPH-Rtrend_fluH  \n",
       "...          ...             ...        ...                    ...  \n",
       "5975    quantile           0.850  20509.175  NU_UCSD-GLEAM_AI_FLUH  \n",
       "5976    quantile           0.900  24627.713  NU_UCSD-GLEAM_AI_FLUH  \n",
       "5977    quantile           0.950  32274.821  NU_UCSD-GLEAM_AI_FLUH  \n",
       "5978    quantile           0.975  41471.763  NU_UCSD-GLEAM_AI_FLUH  \n",
       "5979    quantile           0.990  54137.494  NU_UCSD-GLEAM_AI_FLUH  \n",
       "\n",
       "[936146 rows x 9 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d54454-0767-45d8-a775-c464d0722da8",
   "metadata": {},
   "source": [
    "## WIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "998fc876-cdad-4a3c-81e5-b21bcf8e7634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate wis for all forecasts\n",
    "\n",
    "dfwis = pd.DataFrame()\n",
    "for horizon in [0, 1, 2,3]:\n",
    "    for model in models:\n",
    "        for date in dates: \n",
    "            start_week = Week.fromdate(pd.to_datetime(date)) # week of submission date\n",
    "            end_week = start_week + 3 # target end date of last horizon\n",
    "            \n",
    "            # filter by horizon, model and submission date\n",
    "            pred = predsall[(predsall.horizon==horizon) & (predsall.Model == model) & \\\n",
    "                            (predsall.reference_date == date)]\n",
    "            if len(pred)==0:\n",
    "                continue\n",
    "            \n",
    "            # calculate wis for each week\n",
    "            test = Scoring(df=pred, obsdf=surv, target='hosp',\n",
    "                            start_week = start_week, end_week = end_week)\n",
    "\n",
    "            out = test.organize_timestamped_scores(want_scores = ['wis'], models = [model])\n",
    "            \n",
    "            out['horizon'] = horizon\n",
    "            out['reference_date'] = date\n",
    "            \n",
    "            dfwis = pd.concat([dfwis, out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0033cdb-02d3-42b0-827e-91b2b1deab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwis.to_csv('./WIS.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f028da7-0699-4d7d-b8ef-64e55b4377f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>location</th>\n",
       "      <th>target_end_date</th>\n",
       "      <th>wis</th>\n",
       "      <th>horizon</th>\n",
       "      <th>reference_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>01</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>1.912889</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>02</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>3.405661</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>04</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>23.574783</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>05</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>3.179565</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>06</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>6.374348</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>53</td>\n",
       "      <td>2023-12-23</td>\n",
       "      <td>79.365652</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>54</td>\n",
       "      <td>2023-12-23</td>\n",
       "      <td>53.268863</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>55</td>\n",
       "      <td>2023-12-23</td>\n",
       "      <td>113.721773</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>56</td>\n",
       "      <td>2023-12-23</td>\n",
       "      <td>37.325938</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>US</td>\n",
       "      <td>2023-12-23</td>\n",
       "      <td>3188.119640</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-12-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33232 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model location target_end_date          wis  horizon  \\\n",
       "0        CEPH-Rtrend_fluH       01      2024-04-27     1.912889        0   \n",
       "1        CEPH-Rtrend_fluH       02      2024-04-27     3.405661        0   \n",
       "2        CEPH-Rtrend_fluH       04      2024-04-27    23.574783        0   \n",
       "3        CEPH-Rtrend_fluH       05      2024-04-27     3.179565        0   \n",
       "4        CEPH-Rtrend_fluH       06      2024-04-27     6.374348        0   \n",
       "..                    ...      ...             ...          ...      ...   \n",
       "47  NU_UCSD-GLEAM_AI_FLUH       53      2023-12-23    79.365652        3   \n",
       "48  NU_UCSD-GLEAM_AI_FLUH       54      2023-12-23    53.268863        3   \n",
       "49  NU_UCSD-GLEAM_AI_FLUH       55      2023-12-23   113.721773        3   \n",
       "50  NU_UCSD-GLEAM_AI_FLUH       56      2023-12-23    37.325938        3   \n",
       "51  NU_UCSD-GLEAM_AI_FLUH       US      2023-12-23  3188.119640        3   \n",
       "\n",
       "   reference_date  \n",
       "0      2024-04-27  \n",
       "1      2024-04-27  \n",
       "2      2024-04-27  \n",
       "3      2024-04-27  \n",
       "4      2024-04-27  \n",
       "..            ...  \n",
       "47     2023-12-02  \n",
       "48     2023-12-02  \n",
       "49     2023-12-02  \n",
       "50     2023-12-02  \n",
       "51     2023-12-02  \n",
       "\n",
       "[33232 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ee3316-8513-4a97-ae00-623d05d0b606",
   "metadata": {},
   "source": [
    "## WIS Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7bdaa32c-25c0-413c-9f48-51a354682ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute wis ratio, comparing the Flusight models' forecast scores to the Flusight baseline model\n",
    "# divide flusight models by flusight baseline WIS scores at each location, week, horizon, location\n",
    "dfwis = pd.read_csv('./WIS.csv')\n",
    "baseline = dfwis[dfwis.Model == 'FluSight-baseline'] \n",
    "baseline = baseline.rename(columns={'wis':'wis_baseline', 'Model':'baseline'})\n",
    "dfwis_test = dfwis[dfwis.Model != 'FluSight-baseline']\n",
    "\n",
    "dfwis_ratio = pd.merge(dfwis_test, baseline, how='inner', on = ['location', 'target_end_date',\n",
    "                                                                'horizon', 'reference_date'])\n",
    "\n",
    "# calculate wis ratio\n",
    "dfwis_ratio['wis_ratio'] = dfwis_ratio['wis']/dfwis_ratio['wis_baseline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ef766a4-de11-465c-8188-7bff9402806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwis_ratio.to_csv('./WIS_ratio.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e13e46d-a6ef-4f18-8c0f-258cb38409e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>location</th>\n",
       "      <th>target_end_date</th>\n",
       "      <th>wis</th>\n",
       "      <th>horizon</th>\n",
       "      <th>reference_date</th>\n",
       "      <th>baseline</th>\n",
       "      <th>wis_baseline</th>\n",
       "      <th>wis_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>01</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>1.912889</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>FluSight-baseline</td>\n",
       "      <td>3.186017</td>\n",
       "      <td>0.600401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FluSight-ensemble</td>\n",
       "      <td>01</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>2.005467</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>FluSight-baseline</td>\n",
       "      <td>3.186017</td>\n",
       "      <td>0.629459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MIGHTE-Nsemble</td>\n",
       "      <td>01</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>2.774675</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>FluSight-baseline</td>\n",
       "      <td>3.186017</td>\n",
       "      <td>0.870891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MOBS-GLEAM_FLUH</td>\n",
       "      <td>01</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>9.271692</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>FluSight-baseline</td>\n",
       "      <td>3.186017</td>\n",
       "      <td>2.910120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>01</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>6.820537</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>FluSight-baseline</td>\n",
       "      <td>3.186017</td>\n",
       "      <td>2.140772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27397</th>\n",
       "      <td>MIGHTE-Nsemble</td>\n",
       "      <td>72</td>\n",
       "      <td>2023-11-04</td>\n",
       "      <td>29.624689</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-10-14</td>\n",
       "      <td>FluSight-baseline</td>\n",
       "      <td>24.647738</td>\n",
       "      <td>1.201923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27398</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>US</td>\n",
       "      <td>2023-11-04</td>\n",
       "      <td>437.658750</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-10-14</td>\n",
       "      <td>FluSight-baseline</td>\n",
       "      <td>551.338550</td>\n",
       "      <td>0.793811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27399</th>\n",
       "      <td>FluSight-ensemble</td>\n",
       "      <td>US</td>\n",
       "      <td>2023-11-04</td>\n",
       "      <td>275.942167</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-10-14</td>\n",
       "      <td>FluSight-baseline</td>\n",
       "      <td>551.338550</td>\n",
       "      <td>0.500495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27400</th>\n",
       "      <td>MIGHTE-Nsemble</td>\n",
       "      <td>US</td>\n",
       "      <td>2023-11-04</td>\n",
       "      <td>230.569058</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-10-14</td>\n",
       "      <td>FluSight-baseline</td>\n",
       "      <td>551.338550</td>\n",
       "      <td>0.418199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27401</th>\n",
       "      <td>MOBS-GLEAM_FLUH</td>\n",
       "      <td>US</td>\n",
       "      <td>2023-11-04</td>\n",
       "      <td>2258.267982</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-10-14</td>\n",
       "      <td>FluSight-baseline</td>\n",
       "      <td>551.338550</td>\n",
       "      <td>4.095973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27402 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model location target_end_date          wis  horizon  \\\n",
       "0           CEPH-Rtrend_fluH       01      2024-04-27     1.912889        0   \n",
       "1          FluSight-ensemble       01      2024-04-27     2.005467        0   \n",
       "2             MIGHTE-Nsemble       01      2024-04-27     2.774675        0   \n",
       "3            MOBS-GLEAM_FLUH       01      2024-04-27     9.271692        0   \n",
       "4      NU_UCSD-GLEAM_AI_FLUH       01      2024-04-27     6.820537        0   \n",
       "...                      ...      ...             ...          ...      ...   \n",
       "27397         MIGHTE-Nsemble       72      2023-11-04    29.624689        3   \n",
       "27398       CEPH-Rtrend_fluH       US      2023-11-04   437.658750        3   \n",
       "27399      FluSight-ensemble       US      2023-11-04   275.942167        3   \n",
       "27400         MIGHTE-Nsemble       US      2023-11-04   230.569058        3   \n",
       "27401        MOBS-GLEAM_FLUH       US      2023-11-04  2258.267982        3   \n",
       "\n",
       "      reference_date           baseline  wis_baseline  wis_ratio  \n",
       "0         2024-04-27  FluSight-baseline      3.186017   0.600401  \n",
       "1         2024-04-27  FluSight-baseline      3.186017   0.629459  \n",
       "2         2024-04-27  FluSight-baseline      3.186017   0.870891  \n",
       "3         2024-04-27  FluSight-baseline      3.186017   2.910120  \n",
       "4         2024-04-27  FluSight-baseline      3.186017   2.140772  \n",
       "...              ...                ...           ...        ...  \n",
       "27397     2023-10-14  FluSight-baseline     24.647738   1.201923  \n",
       "27398     2023-10-14  FluSight-baseline    551.338550   0.793811  \n",
       "27399     2023-10-14  FluSight-baseline    551.338550   0.500495  \n",
       "27400     2023-10-14  FluSight-baseline    551.338550   0.418199  \n",
       "27401     2023-10-14  FluSight-baseline    551.338550   4.095973  \n",
       "\n",
       "[27402 rows x 9 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwis_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abed6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9210ecf5-de59-4228-a65d-ba10ba3c9962",
   "metadata": {},
   "source": [
    "## Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6771a6cc-0993-4180-8cf1-3a32389408b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcoverage = pd.DataFrame()\n",
    "\n",
    "for date in dates:\n",
    "    for model in models:\n",
    "         \n",
    "        start_week = Week.fromdate(pd.to_datetime(date)) # week of submission date\n",
    "        end_week = start_week + 3 # target end date of last horizon\n",
    "\n",
    "        # filter by model and submission date, only look at horizon 0-3\n",
    "        pred = predsall[(predsall.Model == model) & \\\n",
    "                        (predsall.reference_date == date) & (predsall.horizon >=0)]\n",
    "        if len(pred)==0:\n",
    "            continue\n",
    "\n",
    "        # calculate wis for each week\n",
    "        test = Scoring(df=pred, obsdf=surv, target='hosp',  \n",
    "                        start_week = start_week, end_week = end_week)\n",
    "\n",
    "        out = test.organize_average_scores(want_scores=['10_cov', '20_cov', '30_cov', '40_cov', '50_cov',\n",
    "            '60_cov', '70_cov', '80_cov', '90_cov', '95_cov', '98_cov'], models = [model])\n",
    "\n",
    "        out['horizon'] = horizon\n",
    "        out['reference_date'] = date\n",
    "\n",
    "        dfcoverage = pd.concat([dfcoverage, out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e655b66-10f5-436a-b87e-f91e681ad909",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcoverage.to_csv('./coverage.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3dcc00f5-e4a7-45a6-9356-286644b2bb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>location</th>\n",
       "      <th>10_cov</th>\n",
       "      <th>20_cov</th>\n",
       "      <th>30_cov</th>\n",
       "      <th>40_cov</th>\n",
       "      <th>50_cov</th>\n",
       "      <th>60_cov</th>\n",
       "      <th>70_cov</th>\n",
       "      <th>80_cov</th>\n",
       "      <th>90_cov</th>\n",
       "      <th>95_cov</th>\n",
       "      <th>98_cov</th>\n",
       "      <th>horizon</th>\n",
       "      <th>reference_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>MOBS-GLEAM_FLUH</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>MOBS-GLEAM_FLUH</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>MOBS-GLEAM_FLUH</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>MOBS-GLEAM_FLUH</td>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>MOBS-GLEAM_FLUH</td>\n",
       "      <td>US</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-10-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8679 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model location  10_cov  20_cov  30_cov  40_cov  50_cov  60_cov  \\\n",
       "0   CEPH-Rtrend_fluH       01     0.0    1.00    1.00    1.00     1.0     1.0   \n",
       "1   CEPH-Rtrend_fluH       02     0.0    0.00    0.00    0.00     0.0     0.0   \n",
       "2   CEPH-Rtrend_fluH       04     0.0    0.00    0.00    0.00     0.0     0.0   \n",
       "3   CEPH-Rtrend_fluH       05     0.0    0.00    0.00    1.00     1.0     1.0   \n",
       "4   CEPH-Rtrend_fluH       06     1.0    1.00    1.00    1.00     1.0     1.0   \n",
       "..               ...      ...     ...     ...     ...     ...     ...     ...   \n",
       "47   MOBS-GLEAM_FLUH       53     0.0    0.00    0.00    0.00     0.0     0.0   \n",
       "48   MOBS-GLEAM_FLUH       54     0.0    0.25    0.25    0.25     0.5     0.5   \n",
       "49   MOBS-GLEAM_FLUH       55     0.0    0.00    0.00    0.00     0.0     0.0   \n",
       "50   MOBS-GLEAM_FLUH       56     0.0    0.00    0.00    0.25     0.5     0.5   \n",
       "51   MOBS-GLEAM_FLUH       US     0.0    0.00    0.25    0.50     1.0     1.0   \n",
       "\n",
       "    70_cov  80_cov  90_cov  95_cov  98_cov  horizon reference_date  \n",
       "0     1.00    1.00    1.00    1.00    1.00        3     2024-04-27  \n",
       "1     0.00    1.00    1.00    1.00    1.00        3     2024-04-27  \n",
       "2     0.00    0.00    0.00    1.00    1.00        3     2024-04-27  \n",
       "3     1.00    1.00    1.00    1.00    1.00        3     2024-04-27  \n",
       "4     1.00    1.00    1.00    1.00    1.00        3     2024-04-27  \n",
       "..     ...     ...     ...     ...     ...      ...            ...  \n",
       "47    0.00    0.00    0.25    0.25    0.50        3     2023-10-14  \n",
       "48    0.50    1.00    1.00    1.00    1.00        3     2023-10-14  \n",
       "49    0.25    0.25    0.25    0.25    0.75        3     2023-10-14  \n",
       "50    0.50    0.50    0.75    0.75    0.75        3     2023-10-14  \n",
       "51    1.00    1.00    1.00    1.00    1.00        3     2023-10-14  \n",
       "\n",
       "[8679 rows x 15 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcoverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bab22c",
   "metadata": {},
   "source": [
    "# MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed5fb010",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate MAPE for all forecasts\n",
    "\n",
    "dfmape = pd.DataFrame()\n",
    "#dic = {}\n",
    "for horizon in [0, 1, 2,3]:\n",
    "    for model in models:\n",
    "        for date in dates: \n",
    "            start_week = Week.fromdate(pd.to_datetime(date)) # week of submission date\n",
    "            end_week = start_week + 3 # target end date of last horizon\n",
    "            \n",
    "            # filter by horizon, model and submission date\n",
    "            pred = predsall[(predsall.horizon==horizon) & (predsall.Model == model) & \\\n",
    "                            (predsall.reference_date == date)]\n",
    "            if len(pred)==0:\n",
    "                continue\n",
    "            \n",
    "            # calculate mape for each week\n",
    "            test = Scoring(df=pred, obsdf=surv, target='hosp',\n",
    "                            start_week = start_week, end_week = end_week)\n",
    "\n",
    "            out = test.get_mape()\n",
    "            \n",
    "            out['horizon'] = horizon\n",
    "            out['reference_date'] = date\n",
    "            \n",
    "            dfmape = pd.concat([dfmape, out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb310c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmape.to_csv('./MAPE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42c04295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Location</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>horizon</th>\n",
       "      <th>reference_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>01</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>02</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>04</td>\n",
       "      <td>0.367925</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>05</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CEPH-Rtrend_fluH</td>\n",
       "      <td>06</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>53</td>\n",
       "      <td>0.700116</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>54</td>\n",
       "      <td>0.821854</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>55</td>\n",
       "      <td>0.768278</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>56</td>\n",
       "      <td>2.546345</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>NU_UCSD-GLEAM_AI_FLUH</td>\n",
       "      <td>US</td>\n",
       "      <td>0.403855</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-12-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32582 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model Location      MAPE  horizon reference_date\n",
       "0        CEPH-Rtrend_fluH       01  0.125000        0     2024-04-27\n",
       "1        CEPH-Rtrend_fluH       02  2.000000        0     2024-04-27\n",
       "2        CEPH-Rtrend_fluH       04  0.367925        0     2024-04-27\n",
       "3        CEPH-Rtrend_fluH       05  0.200000        0     2024-04-27\n",
       "4        CEPH-Rtrend_fluH       06  0.013245        0     2024-04-27\n",
       "..                    ...      ...       ...      ...            ...\n",
       "47  NU_UCSD-GLEAM_AI_FLUH       53  0.700116        3     2023-12-02\n",
       "48  NU_UCSD-GLEAM_AI_FLUH       54  0.821854        3     2023-12-02\n",
       "49  NU_UCSD-GLEAM_AI_FLUH       55  0.768278        3     2023-12-02\n",
       "50  NU_UCSD-GLEAM_AI_FLUH       56  2.546345        3     2023-12-02\n",
       "51  NU_UCSD-GLEAM_AI_FLUH       US  0.403855        3     2023-12-02\n",
       "\n",
       "[32582 rows x 5 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231a2e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8cb375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
